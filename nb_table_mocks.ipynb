{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772f5577-75d2-4b12-af0f-e81fd4ffc163",
   "metadata": {},
   "source": [
    "# **LaTeX table with the BAO-fit results**\n",
    "\n",
    "This notebook shows how to create a LaTeX table with the BAO-fit results from a set of mocks. It also makes some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38b764-ac2c-49b9-affd-352119f0bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806ed1ce-cc99-4dbb-83f7-91279d046c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c8ef6-d682-4355-960d-79401c2b63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils_data import RedshiftDistributions, GetThetaLimits\n",
    "from utils_baofit import BAOFitInitializer\n",
    "\n",
    "# # Option A. DESY6-related stuff\n",
    "# dataset_mocks_list = [\"DESY6_COLA\"]\n",
    "# # dataset_mocks_list = [\"DESY6_COLA_DR1tiles_noDESI\"]\n",
    "# # dataset_mocks_list = [\"DESY6_COLA_DR1tiles_DESIonly\"]\n",
    "# # dataset_mocks_list = [\"DESY6_COLA_dec_below-23.5\"]\n",
    "# # dataset_mocks_list = [\"DESY6_COLA_dec_above-23.5\"]\n",
    "# dataset_mocks_list = [\"DESY6_COLA\", \"DESY6_COLA_DR1tiles_noDESI\", \"DESY6_COLA_DR1tiles_DESIonly\", \"DESY6_COLA_dec_below-23.5\", \"DESY6_COLA_dec_above-23.5\"]\n",
    "# dynamical_theta_limits = False\n",
    "# old_template = \"_old\"\n",
    "# # old_template = \"\"\n",
    "# delta_z = None # only for DESI stuff\n",
    "\n",
    "# Option B. DESI-related stuff\n",
    "delta_z = 0.02\n",
    "# dataset_mocks_list = [f\"DESIY1_LRG_Abacus_altmtl_deltaz{delta_z}\"]\n",
    "# dataset_mocks_list = [f\"DESIY1_LRG_EZ_ffa_deltaz{delta_z}\"]\n",
    "# dataset_mocks_list = [f\"DESIY1_LRG_Abacus_complete_deltaz{delta_z}\"]\n",
    "# dataset_mocks_list = [f\"DESIY1_LRG_EZ_complete_deltaz{delta_z}\"]\n",
    "# dataset_mocks_list = [f\"DESIY1_LRG_Abacus_altmtl_deltaz{delta_z}\", f\"DESIY1_LRG_EZ_ffa_deltaz{delta_z}\", f\"DESIY1_LRG_Abacus_complete_deltaz{delta_z}\", f\"DESIY1_LRG_EZ_complete_deltaz{delta_z}\"]\n",
    "# dataset_mocks_list = [f\"DESIY1_LRG_Abacus_altmtl_deltaz{delta_z}\", f\"DESIY1_LRG_Abacus_altmtl_deltaz{delta_z}_LRG1\", f\"DESIY1_LRG_Abacus_altmtl_deltaz{delta_z}_LRG2\", f\"DESIY1_LRG_Abacus_altmtl_deltaz{delta_z}_LRG3\"]\n",
    "dataset_mocks_list = [f\"DESIY1_LRG_EZ_ffa_deltaz{delta_z}\", f\"DESIY1_LRG_EZ_ffa_deltaz{delta_z}_LRG1\", f\"DESIY1_LRG_EZ_ffa_deltaz{delta_z}_LRG2\", f\"DESIY1_LRG_EZ_ffa_deltaz{delta_z}_LRG3\"]\n",
    "dynamical_theta_limits = True\n",
    "\n",
    "\n",
    "fit_results = {}\n",
    "mock_id_detected_list = {}\n",
    "\n",
    "for dataset in dataset_mocks_list:\n",
    "\n",
    "    dataset_orig = dataset\n",
    "    bins_removed = []\n",
    "\n",
    "    if delta_z is not None:\n",
    "        if delta_z == 0.028:\n",
    "            if \"DESIY1\" in dataset:\n",
    "                if \"LRG1\" in dataset:\n",
    "                    bins_removed = list(map(int, np.arange(7, 25)))  # LRG1\n",
    "                    dataset_orig = dataset.replace(\"_LRG1\", \"\")\n",
    "                elif \"LRG2\" in dataset:\n",
    "                    bins_removed = list(map(int, np.concatenate([np.arange(0, 7), np.arange(14, 25)])))  # LRG2\n",
    "                    dataset_orig = dataset.replace(\"_LRG2\", \"\")\n",
    "                elif \"LRG3\" in dataset:\n",
    "                    bins_removed = list(map(int, np.arange(0, 14)))  # LRG3\n",
    "                    dataset_orig = dataset.replace(\"_LRG3\", \"\")\n",
    "        elif delta_z == 0.02:\n",
    "            if \"DESIY1\" in dataset:\n",
    "                if \"LRG1\" in dataset:\n",
    "                    bins_removed = list(map(int, np.arange(10, 35)))  # LRG1\n",
    "                    dataset_orig = dataset.replace(\"_LRG1\", \"\")\n",
    "                elif \"LRG2\" in dataset:\n",
    "                    bins_removed = list(map(int, np.concatenate([np.arange(0, 10), np.arange(20, 35)])))  # LRG2\n",
    "                    dataset_orig = dataset.replace(\"_LRG2\", \"\")\n",
    "                elif \"LRG3\" in dataset:\n",
    "                    bins_removed = list(map(int, np.arange(0, 20)))  # LRG3\n",
    "                    dataset_orig = dataset.replace(\"_LRG3\", \"\")\n",
    "\n",
    "    print(f\"Loading the results for the {dataset} data set...\")\n",
    "\n",
    "    if \"DESIY1\" in dataset:\n",
    "        nz_flag = \"mocks\"\n",
    "        cov_type = \"mocks\"\n",
    "        cosmology_template = \"desifid\"\n",
    "        cosmology_covariance = \"desifid\"\n",
    "    \n",
    "        if \"EZ\" in dataset:\n",
    "            n_mocks = 1000\n",
    "        elif \"Abacus\" in dataset:\n",
    "            n_mocks = 25\n",
    "        \n",
    "    elif \"DESY6\" in dataset:\n",
    "        nz_flag = \"mocks\"\n",
    "        cov_type = \"cosmolike\"\n",
    "        # cov_type = \"mocks\"\n",
    "        cosmology_template = \"mice\" + old_template\n",
    "        cosmology_covariance = \"mice\"\n",
    "        \n",
    "        n_mocks = 1952\n",
    "\n",
    "    theta_min, theta_max = GetThetaLimits(dataset=dataset_orig, nz_flag=nz_flag, dynamical_theta_limits=dynamical_theta_limits).get_theta_limits()\n",
    "    \n",
    "    mock_id_list = [\"mean\"] + list(range(n_mocks))\n",
    "    mock_id_detected_list[dataset] = []\n",
    "        \n",
    "    fit_results[dataset] = {}\n",
    "    \n",
    "    for mock_id in mock_id_list:\n",
    "        # 1. Arguments\n",
    "        class Args:\n",
    "            def __init__(self):\n",
    "                self.include_wiggles = \"y\"\n",
    "                self.dataset = dataset_orig\n",
    "                self.weight_type = 1 # it will not be used...\n",
    "                self.mock_id = mock_id\n",
    "                self.nz_flag = nz_flag\n",
    "                self.cov_type = cov_type\n",
    "                self.cosmology_template = cosmology_template\n",
    "                self.cosmology_covariance = cosmology_covariance\n",
    "                self.delta_theta = 0.2\n",
    "                self.theta_min = theta_min\n",
    "                self.theta_max = theta_max\n",
    "                self.pow_broadband = [-2, -1, 0, 1]\n",
    "                self.bins_removed = bins_removed\n",
    "                self.diag_only = \"n\"\n",
    "                self.remove_crosscov = \"n\"\n",
    "                self.alpha_min = 0.8\n",
    "                self.alpha_max = 1.2\n",
    "                self.base_path = None\n",
    "        args = Args()\n",
    "        args.include_wiggles = \"\" if args.include_wiggles == \"y\" else \"_nowiggles\"\n",
    "        \n",
    "        # 2. BAO fit initializer. This basically creates the path to load the results\n",
    "        baofit_initializer = BAOFitInitializer(\n",
    "            include_wiggles=args.include_wiggles,\n",
    "            dataset=args.dataset,\n",
    "            weight_type=args.weight_type,\n",
    "            mock_id=args.mock_id,\n",
    "            nz_flag=args.nz_flag,\n",
    "            cov_type=args.cov_type,\n",
    "            cosmology_template=args.cosmology_template,\n",
    "            cosmology_covariance=args.cosmology_covariance,\n",
    "            delta_theta=args.delta_theta,\n",
    "            theta_min=args.theta_min,\n",
    "            theta_max=args.theta_max,\n",
    "            pow_broadband=args.pow_broadband,\n",
    "            bins_removed=args.bins_removed,\n",
    "            alpha_min=args.alpha_min,\n",
    "            alpha_max=args.alpha_max,\n",
    "            verbose=False,\n",
    "            base_path=args.base_path,\n",
    "        )\n",
    "    \n",
    "        try:\n",
    "            results = np.loadtxt(os.path.join(baofit_initializer.path_baofit, \"fit_results.txt\"))\n",
    "            if not os.path.exists(os.path.join(baofit_initializer.path_baofit, \"wtheta_data_bestfit.txt\")):\n",
    "                # print(f\"Mock number {mock_id} has a non-detection! See {baofit_initializer.path_baofit}\")\n",
    "                print(f\"Mock number {mock_id} has a non-detection!\")\n",
    "            else:\n",
    "                fit_results[dataset][mock_id] = results\n",
    "                if mock_id != \"mean\":\n",
    "                    mock_id_detected_list[dataset].append(mock_id)\n",
    "                \n",
    "        except:\n",
    "            break\n",
    "            \n",
    "    print(f\"Last mock available for the {dataset} data set: {mock_id}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8449b24b-0431-4f2b-86b0-26024eff2b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9b199-dce4-47cf-8a4e-14adbfacfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset in dataset_mocks_list:\n",
    "\n",
    "#     data = []\n",
    "#     for key, results in fit_results[dataset].items():\n",
    "#         mock_id = key\n",
    "#         alpha, sigma_alpha, chi2, dof = results\n",
    "#         data.append([mock_id, alpha, sigma_alpha, chi2, int(dof)])\n",
    "    \n",
    "#     df = pd.DataFrame(data, columns=[\"Mock id\", r\"$\\alpha$\", r\"$\\sigma_\\alpha$\", r\"$\\chi^2$\", \"dof\"])\n",
    "    \n",
    "#     df[r\"$\\alpha$\"] = df[r\"$\\alpha$\"].map(lambda x: f\"{x:.3f}\")\n",
    "#     df[r\"$\\sigma_\\alpha$\"] = df[r\"$\\sigma_\\alpha$\"].map(lambda x: f\"{x:.3f}\")\n",
    "#     df[r\"$\\chi^2$\"] = df[r\"$\\chi^2$\"].map(lambda x: f\"{x:.1f}\")\n",
    "#     df[\"dof\"] = df[\"dof\"].astype(int)\n",
    "    \n",
    "#     latex_table = df.to_latex(index=False, escape=False, column_format=\"c|cccc\")\n",
    "\n",
    "#     # print(f\"LaTeX table for the {dataset} data set:\\n\")\n",
    "#     # print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab564ae8-b1a9-4d70-9bd5-1df8c6d2797f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f7d7b-a959-45b8-9b99-0554a90d5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for dataset in dataset_mocks_list:\n",
    "    alpha_mocks = []\n",
    "    sigma_alpha_mocks = []\n",
    "    chi2s = []\n",
    "    dofs = []\n",
    "\n",
    "    for mock_id, results in fit_results[dataset].items():\n",
    "        alpha, sigma_alpha, chi2, dof = results\n",
    "        if mock_id == \"mean\":\n",
    "            alpha_mean_mocks = alpha\n",
    "            sigma_alpha_mean_mocks = sigma_alpha\n",
    "            chi2_mean_mocks = chi2\n",
    "            dof_mean_mocks = dof\n",
    "        else:\n",
    "            alpha_mocks.append(alpha)\n",
    "            sigma_alpha_mocks.append(sigma_alpha)\n",
    "            chi2s.append(chi2)\n",
    "            dofs.append(dof)\n",
    "\n",
    "    alpha_mocks = np.array(alpha_mocks)\n",
    "    sigma_alpha_mocks = np.array(sigma_alpha_mocks)\n",
    "    chi2s = np.array(chi2s)\n",
    "    dofs = np.array(dofs)\n",
    "\n",
    "    alpha_mean = alpha_mocks.mean()\n",
    "    sigma_std = alpha_mocks.std()\n",
    "\n",
    "    upper, lower = np.percentile(alpha_mocks, [84.075, 15.825], method=\"linear\")\n",
    "    sigma_68 = (upper - lower) / 2\n",
    "\n",
    "    mean_sigma_alpha = sigma_alpha_mocks.mean()\n",
    "\n",
    "    frac_enc = np.mean(\n",
    "        (alpha_mocks > alpha_mean - mean_sigma_alpha) &\n",
    "        (alpha_mocks < alpha_mean + mean_sigma_alpha)\n",
    "    ) * 100\n",
    "\n",
    "    d_norm = (alpha_mocks - alpha_mean) / sigma_alpha_mocks\n",
    "    dnorm_mean = d_norm.mean()\n",
    "    dnorm_std = d_norm.std()\n",
    "\n",
    "    mean_chi2 = chi2s.mean()\n",
    "    mean_dof = dofs.mean() # they should all be the same...\n",
    "    chi2_over_dof_str = f\"{mean_chi2:.1f}/{int(round(mean_dof))}\"\n",
    "\n",
    "    alpha_mean_pm_sigma = f\"{alpha_mean_mocks:.4f} ± {sigma_alpha_mean_mocks:.4f}\"\n",
    "    chi2_over_dof_str_mean = f\"{chi2_mean_mocks:.1f}/{int(round(dof_mean_mocks))}\"\n",
    "\n",
    "    summary_data.append([\n",
    "        dataset,\n",
    "        alpha_mean,\n",
    "        sigma_std,\n",
    "        sigma_68,\n",
    "        mean_sigma_alpha,\n",
    "        frac_enc,\n",
    "        dnorm_mean,\n",
    "        dnorm_std,\n",
    "        chi2_over_dof_str,\n",
    "        alpha_mean_pm_sigma,\n",
    "        chi2_over_dof_str_mean\n",
    "    ])\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data, columns=[\n",
    "    \"Dataset\",\n",
    "    r\"$\\langle\\alpha\\rangle$\",\n",
    "    r\"$\\sigma_{\\rm std}$\",\n",
    "    r\"$\\sigma_{68}$\",\n",
    "    r\"$\\langle\\sigma_\\alpha\\rangle$\",\n",
    "    r\"fraction encl.$\\langle\\alpha\\rangle$ [\\%]\",\n",
    "    r\"$\\langle d_{\\rm norm}\\rangle$\",\n",
    "    r\"$\\sigma_{d_{\\rm norm}}$\",\n",
    "    r\"$\\langle\\chi^2\\rangle/$dof\",\n",
    "    \"Mean of mocks\",\n",
    "    r\"$\\chi^2_{\\rm mean\\ mocks}/$dof\",\n",
    "])\n",
    "\n",
    "# Format columns\n",
    "for col in [\n",
    "    r\"$\\langle\\alpha\\rangle$\",\n",
    "    r\"$\\sigma_{\\rm std}$\",\n",
    "    r\"$\\sigma_{68}$\",\n",
    "    r\"$\\langle\\sigma_\\alpha\\rangle$\"\n",
    "]:\n",
    "    summary_df[col] = summary_df[col].map(lambda x: f\"{float(x):.4f}\")\n",
    "\n",
    "summary_df[r\"fraction encl.$\\langle\\alpha\\rangle$ [\\%]\"] = summary_df[\n",
    "    r\"fraction encl.$\\langle\\alpha\\rangle$ [\\%]\"].map(lambda x: f\"{float(x):.1f}\")\n",
    "\n",
    "summary_df[r\"$\\langle d_{\\rm norm}\\rangle$\"] = summary_df[\n",
    "    r\"$\\langle d_{\\rm norm}\\rangle$\"].map(lambda x: f\"{float(x):.4f}\")\n",
    "\n",
    "summary_df[r\"$\\sigma_{d_{\\rm norm}}$\"] = summary_df[\n",
    "    r\"$\\sigma_{d_{\\rm norm}}$\"].map(lambda x: f\"{float(x):.4f}\")\n",
    "\n",
    "# Output LaTeX table\n",
    "latex_table = summary_df.to_latex(index=False, escape=False, column_format=\"l|\" + \"c\" * (len(summary_df.columns) - 1))\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315f9d0-df7b-49aa-867a-91da273027fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a1e0d-9ec6-4482-8dbd-7f3324bf0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.serif\"] = \"Times New Roman\"\n",
    "import scipy\n",
    "\n",
    "figsize = (18, 5)\n",
    "\n",
    "for dataset in dataset_mocks_list:\n",
    "\n",
    "    # Compute means\n",
    "    mean_alpha = np.mean([fit_results[dataset][mock_id][0] for mock_id in mock_id_detected_list[dataset]])\n",
    "    mean_sigma_alpha = np.mean([fit_results[dataset][mock_id][1] for mock_id in mock_id_detected_list[dataset]])\n",
    "    mean_chi2 = np.mean([fit_results[dataset][mock_id][2] for mock_id in mock_id_detected_list[dataset]])\n",
    "    \n",
    "    # Create 1x3 subplot grid\n",
    "    fig, axs = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "    fig.suptitle(fr\"\\texttt{{{dataset}}}\", fontsize=20)\n",
    "    \n",
    "    # Histogram for alpha\n",
    "    axs[0].hist([fit_results[dataset][mock_id][0] for mock_id in mock_id_detected_list[dataset]], \n",
    "                color='royalblue', edgecolor='black', alpha=0.7)\n",
    "    axs[0].axvline(mean_alpha, color='black', linestyle=\"--\", linewidth=2, label=fr'$\\langle\\alpha\\rangle$ = {mean_alpha:.4f}')\n",
    "    axs[0].set_xlabel(r'$\\alpha$', fontsize=18)\n",
    "    axs[0].tick_params(axis='both', labelsize=14)\n",
    "    axs[0].legend(fontsize=14)\n",
    "    \n",
    "    # Histogram for sigma_alpha\n",
    "    axs[1].hist([fit_results[dataset][mock_id][1] for mock_id in mock_id_detected_list[dataset]], \n",
    "                color='darkorange', edgecolor='black', alpha=0.7)\n",
    "    axs[1].axvline(mean_sigma_alpha, color='black', linestyle=\"--\", linewidth=2, label=fr'$\\langle\\sigma_\\alpha\\rangle$ = {mean_sigma_alpha:.4f}')\n",
    "    axs[1].set_xlabel(r'$\\sigma_{\\alpha}$', fontsize=18)\n",
    "    axs[1].tick_params(axis='both', labelsize=14)\n",
    "    axs[1].legend(fontsize=14)\n",
    "    \n",
    "    # Histogram for chi^2\n",
    "    axs[2].hist([fit_results[dataset][mock_id][2] for mock_id in mock_id_detected_list[dataset]], density=True, \n",
    "                color='forestgreen', edgecolor='black', alpha=0.7)\n",
    "    axs[2].axvline(mean_chi2, color='black', linestyle=\"--\", linewidth=2, label=fr'$\\langle\\chi^2\\rangle$ = {mean_chi2:.1f}')\n",
    "    axs[2].set_xlabel(r'$\\chi^2$', fontsize=18)\n",
    "    axs[2].tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    # Overlay chi-squared distribution on the chi2 histogram\n",
    "    dof = fit_results[dataset][mock_id_detected_list[dataset][0]][3]\n",
    "    x = np.linspace(0, dof * 2, 500)\n",
    "    pdf = scipy.stats.chi2.pdf(x, dof)\n",
    "    axs[2].plot(x, pdf, label=fr'$\\chi^2$ dist. (dof = {int(dof)})', color='darkgreen')\n",
    "    axs[2].legend(loc='upper right', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/analysis_{dataset}.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db975548-e9cc-4410-85a2-c2248814646d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a3084-aeb2-4a2c-9556-03c064835855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify rows\n",
    "# full_row = summary_df.iloc[0]  # Full LRG\n",
    "# sub_rows = summary_df.iloc[1:]  # LRG1, LRG2, LRG3\n",
    "\n",
    "# # Extract arrays\n",
    "# alphas = sub_rows[r\"$\\langle\\alpha\\rangle$\"].astype(float).values\n",
    "# sigmas = sub_rows[r\"$\\langle\\sigma_\\alpha\\rangle$\"].astype(float).values\n",
    "\n",
    "# # Compute weights (inverse variance)\n",
    "# weights = 1.0 / (sigmas**2)\n",
    "\n",
    "# # Combined alpha and sigma\n",
    "# alpha_comb = np.sum(alphas * weights) / np.sum(weights)\n",
    "# sigma_comb = np.sqrt(1.0 / np.sum(weights))\n",
    "\n",
    "# # Extract full LRG values\n",
    "# full_alpha = float(full_row[r\"$\\langle\\alpha\\rangle$\"])\n",
    "# full_sigma = float(full_row[r\"$\\langle\\sigma_\\alpha\\rangle$\"])\n",
    "\n",
    "# # Print comparison\n",
    "# print(\"=== Comparison ===\")\n",
    "# print(f\"Full LRG:    alpha = {full_alpha:.4f}, sigma_alpha = {full_sigma:.4f}\")\n",
    "# print(f\"Combined:    alpha = {alpha_comb:.4f}, sigma_alpha = {sigma_comb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aacc2d-c824-4527-a570-9c1dde6062c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd33a017-da8d-49ec-ad5c-8066a420864e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5cfca3-d5ce-4320-aa60-f8bbe79fb2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d60704-a8d6-4d23-8d3f-a1b270536a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a008a-76eb-470f-a4f7-98e175c4a362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62652f-bf7a-4d6d-ae37-662aa9f22efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d011419-b0e7-490c-a3f4-0e402ea10727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef8840-914e-4d6c-955a-919dc638919a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99402ec8-dc65-4c20-a234-37ef9278434b",
   "metadata": {},
   "source": [
    "# **This part is only for my DES stuff**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a6686-298c-4171-a662-1566d2c93111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the data\n",
    "\n",
    "nz_flag = \"fid\"\n",
    "\n",
    "fit_results_data = {}\n",
    "\n",
    "for dataset in dataset_mocks_list:\n",
    "    dataset = dataset.replace('_COLA', '')\n",
    "    \n",
    "    theta_min, theta_max = GetThetaLimits(dataset=dataset, nz_flag=nz_flag, dynamical_theta_limits=dynamical_theta_limits).get_theta_limits()\n",
    "    \n",
    "    # 1. Arguments\n",
    "    class Args:\n",
    "        def __init__(self):\n",
    "            self.include_wiggles = \"y\"\n",
    "            self.dataset = dataset\n",
    "            self.weight_type = 1\n",
    "            self.mock_id = \"mean\" # it will not be used...\n",
    "            self.nz_flag = nz_flag\n",
    "            self.cov_type = \"cosmolike\"\n",
    "            self.cosmology_template = \"planck\" + old_template\n",
    "            self.cosmology_covariance = \"planck\"\n",
    "            self.delta_theta = 0.2\n",
    "            self.theta_min = theta_min\n",
    "            self.theta_max = theta_max\n",
    "            self.pow_broadband = [-2, -1, 0]\n",
    "            self.bins_removed = []\n",
    "            self.diag_only = \"n\"\n",
    "            self.remove_crosscov = \"n\"\n",
    "            self.alpha_min = 0.8\n",
    "            self.alpha_max = 1.2\n",
    "            self.base_path = None\n",
    "    args = Args()\n",
    "    args.include_wiggles = \"\" if args.include_wiggles == \"y\" else \"_nowiggles\"\n",
    "    \n",
    "    # 2. BAO fit initializer. This basically creates the path to load the results\n",
    "    baofit_initializer = BAOFitInitializer(\n",
    "        include_wiggles=args.include_wiggles,\n",
    "        dataset=args.dataset,\n",
    "        weight_type=args.weight_type,\n",
    "        mock_id=args.mock_id,\n",
    "        nz_flag=args.nz_flag,\n",
    "        cov_type=args.cov_type,\n",
    "        cosmology_template=args.cosmology_template,\n",
    "        cosmology_covariance=args.cosmology_covariance,\n",
    "        delta_theta=args.delta_theta,\n",
    "        theta_min=args.theta_min,\n",
    "        theta_max=args.theta_max,\n",
    "        pow_broadband=args.pow_broadband,\n",
    "        bins_removed=args.bins_removed,\n",
    "        alpha_min=args.alpha_min,\n",
    "        alpha_max=args.alpha_max,\n",
    "        verbose=False,\n",
    "        base_path=args.base_path,\n",
    "    )\n",
    "\n",
    "    fit_results_data[dataset] = np.loadtxt(os.path.join(baofit_initializer.path_baofit, \"fit_results.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046400e1-9262-433e-89a5-3643d32dfd20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b94bab-7c80-460a-9c39-857040f93384",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fid = \"DESY6_COLA\"\n",
    "figsize = (5, 4)\n",
    "\n",
    "for dataset in dataset_mocks_list[1:]:\n",
    "\n",
    "    mock_id_detected_list_common = sorted(set(mock_id_detected_list[dataset_fid]) & set(mock_id_detected_list[dataset]))\n",
    "\n",
    "    alpha_mocks_fid = np.array([fit_results[dataset_fid][mock_id][0] for mock_id in mock_id_detected_list_common])\n",
    "    alpha_mocks_dataset = np.array([fit_results[dataset][mock_id][0] for mock_id in mock_id_detected_list_common])\n",
    "    delta_alpha_mocks = alpha_mocks_dataset - alpha_mocks_fid\n",
    "\n",
    "    alpha_data_fid = fit_results_data[dataset_fid.replace('_COLA', '')][0]\n",
    "    alpha_data_dataset = fit_results_data[dataset.replace('_COLA', '')][0]\n",
    "    delta_alpha_data = alpha_data_dataset - alpha_data_fid\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    # plt.title(fr\"\\texttt{{{dataset_fid.replace('_COLA', '')}}} vs. \\texttt{{{dataset.replace('_COLA', '')}}}\", fontsize=20)\n",
    "    plt.title(fr\"\\texttt{{{dataset.replace('_COLA', '').replace('DESY6_', '')}}}\", fontsize=20)\n",
    "\n",
    "    plt.hist(delta_alpha_mocks, edgecolor='black', alpha=0.7, label=\"COLA mocks\", color=\"royalblue\")\n",
    "    plt.axvline(delta_alpha_data, color=\"violet\", linewidth=3, label=\"Data\")\n",
    "\n",
    "    ax.set_xlabel(r'$\\alpha - \\alpha^{\\mathrm{fid}}$', fontsize=18)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "    plt.legend(loc=\"best\", fontsize=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/diff_alpha_{dataset.replace('_COLA', '')}_vs_{dataset_fid.replace('_COLA', '')}.png\")\n",
    "\n",
    "    # pct = np.sum(delta_alpha_mocks > delta_alpha_data) / len(mock_id_detected_list_common) * 100\n",
    "    # print(f\"{pct:.2f}% of the mocks have larger delta alpha\")\n",
    "    \n",
    "    # corr = np.corrcoef(alpha_mocks_fid, alpha_mocks_dataset)[0, 1]\n",
    "    # print(f\"Correlation between {dataset_fid} and {dataset}: {corr:.2f}\")\n",
    "\n",
    "    print(f\"Data delta alpha: {delta_alpha_data*100:.2f}\")\n",
    "    for lower_limit, upper_limit in zip([5, 0.5], [95, 99.5]):\n",
    "        lower, upper = np.percentile(delta_alpha_mocks, [lower_limit, upper_limit])\n",
    "        print(f\"{int(upper_limit - lower_limit)}% interval for mocks: [{lower*100:.2f}, {upper*100:.2f}]\")\n",
    "    percentile = scipy.stats.percentileofscore(delta_alpha_mocks, delta_alpha_data, kind='rank')\n",
    "    print(f\"Percentile of data: {percentile:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc031fc-ae51-4897-bea8-27d4390c0547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d07ea-abac-4a53-85fd-da594240432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fid = \"DESY6_COLA\"\n",
    "figsize = (5, 4)\n",
    "\n",
    "for dataset in dataset_mocks_list[1:]:\n",
    "    \n",
    "    mock_id_detected_list_common = sorted(set(mock_id_detected_list[dataset_fid]) & set(mock_id_detected_list[dataset]))\n",
    "\n",
    "    sigma_alpha_mocks_fid = np.array([fit_results[dataset_fid][mock_id][1] for mock_id in mock_id_detected_list_common])\n",
    "    sigma_alpha_mocks_dataset = np.array([fit_results[dataset][mock_id][1] for mock_id in mock_id_detected_list_common])\n",
    "    ratio_sigma_alpha_mocks = sigma_alpha_mocks_dataset / sigma_alpha_mocks_fid\n",
    "\n",
    "    sigma_alpha_data_fid = fit_results_data[dataset_fid.replace('_COLA', '')][1]\n",
    "    sigma_alpha_data_dataset = fit_results_data[dataset.replace('_COLA', '')][1]\n",
    "    ratio_sigma_alpha_data = sigma_alpha_data_dataset / sigma_alpha_data_fid\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    # plt.title(fr\"\\texttt{{{dataset_fid.replace('_COLA', '')}}} vs. \\texttt{{{dataset.replace('_COLA', '')}}}\", fontsize=20)\n",
    "    plt.title(fr\"\\texttt{{{dataset.replace('_COLA', '').replace('DESY6_', '')}}}\", fontsize=20)\n",
    "\n",
    "    plt.hist(ratio_sigma_alpha_mocks, edgecolor='black', alpha=0.7, label=\"COLA mocks\", color=\"darkorange\")\n",
    "    plt.axvline(ratio_sigma_alpha_data, color=\"violet\", linewidth=3, label=\"Data\")\n",
    "\n",
    "    ax.set_xlabel(r'$\\sigma_\\alpha / \\sigma_\\alpha^{\\mathrm{fid}}$', fontsize=18)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "    plt.legend(loc=\"best\", fontsize=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/ratio_sigma_{dataset.replace('_COLA', '')}_vs_{dataset_fid.replace('_COLA', '')}.png\")\n",
    "\n",
    "    pct = np.sum(ratio_sigma_alpha_mocks > ratio_sigma_alpha_data) / len(mock_id_detected_list_common) * 100\n",
    "    print(f\"{pct:.2f}% of the mocks have a higher sigma_alpha ratio than data\")\n",
    "\n",
    "    print(f\"Data delta alpha: {ratio_sigma_alpha_data:.2f}\")\n",
    "    for lower_limit, upper_limit in zip([5, 0.5], [95, 99.5]):\n",
    "        lower, upper = np.percentile(ratio_sigma_alpha_mocks, [lower_limit, upper_limit])\n",
    "        print(f\"{int(upper_limit - lower_limit)}% interval for mocks: [{lower:.2f}, {upper:.2f}]\")\n",
    "    percentile = scipy.stats.percentileofscore(ratio_sigma_alpha_mocks, ratio_sigma_alpha_data, kind='rank')\n",
    "    print(f\"Percentile of data: {percentile:.2f}%\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb99347-1b0d-4aed-b417-79d8722537d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca69eb4f-932f-44cd-bce5-e36f7aa88943",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5, 4)\n",
    "\n",
    "for dataset in dataset_mocks_list:\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "\n",
    "    plt.title(fr\"\\texttt{{{dataset.replace('_COLA', '')}}}\", fontsize=20)\n",
    "\n",
    "    plt.plot([fit_results[dataset][mock_id][0] for mock_id in mock_id_detected_list[dataset]], [fit_results[dataset][mock_id][1] for mock_id in mock_id_detected_list[dataset]], \".\")\n",
    "\n",
    "    plt.plot(fit_results_data[dataset.replace(\"_COLA\", \"\")][0], fit_results_data[dataset.replace(\"_COLA\", \"\")][1], \"d\")\n",
    "\n",
    "    ax.set_xlabel(r'$\\alpha$', fontsize=18)\n",
    "    ax.set_ylabel(r'$\\sigma_\\alpha$', fontsize=18)\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39d3f4-13f0-425c-bb07-536195717219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d18f8-42fe-47b4-8a19-4811be74f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'DESY6_COLA'\n",
    "\n",
    "sigma_alpha_mean_mocks = {}\n",
    "\n",
    "for dataset in dataset_mocks_list:\n",
    "\n",
    "    sigma_alpha_mean_mocks[dataset] = np.array([fit_results[dataset][mock_id][1] for mock_id in mock_id_detected_list[dataset]]).mean()\n",
    "\n",
    "print(sigma_alpha_mean_mocks['DESY6_COLA'])\n",
    "print(1 / np.sqrt(1 / sigma_alpha_mean_mocks['DESY6_COLA_DR1tiles_noDESI']**2 + 1 / sigma_alpha_mean_mocks['DESY6_COLA_DR1tiles_DESIonly']**2))\n",
    "print(1 / np.sqrt(1 / sigma_alpha_mean_mocks['DESY6_COLA_dec_below-23.5']**2 + 1 / sigma_alpha_mean_mocks['DESY6_COLA_dec_above-23.5']**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aeb220-9f84-4908-b42c-ee4a89978061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac02aa6-9e9a-43fd-976c-5f466155d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'DESY6_COLA'\n",
    "\n",
    "sigma_alpha_mean_mocks = {}\n",
    "\n",
    "for dataset in dataset_mocks_list:\n",
    "\n",
    "    sigma_alpha_mean_mocks[dataset] = fit_results[dataset][15][1]\n",
    "\n",
    "print(sigma_alpha_mean_mocks['DESY6_COLA'])\n",
    "print(1 / np.sqrt(1 / sigma_alpha_mean_mocks['DESY6_COLA_DR1tiles_noDESI']**2 + 1 / sigma_alpha_mean_mocks['DESY6_COLA_DR1tiles_DESIonly']**2))\n",
    "print(1 / np.sqrt(1 / sigma_alpha_mean_mocks['DESY6_COLA_dec_below-23.5']**2 + 1 / sigma_alpha_mean_mocks['DESY6_COLA_dec_above-23.5']**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce379bf-fd05-4b5b-8e8c-38b5d9c0815a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
