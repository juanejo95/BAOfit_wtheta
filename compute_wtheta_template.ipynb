{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1ef46-168d-4c94-ab54-9ba54795980d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "from cosmoprimo import Cosmology, PowerSpectrumBAOFilter\n",
    "import argparse\n",
    "import multiprocessing\n",
    "from utils import savedir_template, cosmology, redshift_distributions\n",
    "\n",
    "# # Parse command-line arguments\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--args.cosmology_template', help='mice, planck or lognormal_Y6BAO', default='mice', type=str)\n",
    "# parser.add_argument('--args.include_wiggles', help='y or n', default='y', type=str)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# args.cosmology_template = args.cosmology_template\n",
    "# args.include_wiggles = '' if args.include_wiggles == 'y' else '_noBAO'\n",
    "\n",
    "# Arguments\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cosmology_template = \"planck\"\n",
    "        self.nz_flag = \"fid\"\n",
    "        self.include_wiggles = \"y\"\n",
    "args = Args()\n",
    "args.include_wiggles = '' if args.include_wiggles == 'y' else '_noBAO'\n",
    "\n",
    "# 0. Path for saving the template\n",
    "savedir = savedir_template(include_wiggles=args.include_wiggles, nz_flag=args.nz_flag, cosmology_template=args.cosmology_template)()\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "\n",
    "# 1. Galaxy bias. I give it random values, since we save the three components of w(theta) separately. However, we use it for checking the results\n",
    "galaxy_bias = {0: 1.3, 1: 1.9, 2: 4, 3: 2.1, 4: 3, 5: 0.7}\n",
    "\n",
    "# 2. Numerical resolution of the calculation\n",
    "\n",
    "# Nz, Nk, Nmu, Nr = 10**3, 2*10**5, 5*10**4, 5*10**4\n",
    "Nz, Nk, Nmu, Nr = 10**3, 10**4, 10**4, 10**4\n",
    "\n",
    "mu_vector = np.linspace(-1, 1, Nmu)\n",
    "legendre = {ell: scipy.special.eval_legendre(ell, mu_vector) for ell in [0, 2, 4]}\n",
    "r_12_vector = 10**np.linspace(np.log10(10**-2), np.log10(10**5), Nr)\n",
    "\n",
    "# 3. Values of theta\n",
    "theta = 10**np.linspace(np.log10(0.001), np.log10(179.5), 10**2) * np.pi/180\n",
    "\n",
    "# 4. Redshift distributions\n",
    "nz_instance = redshift_distributions(args.nz_flag)\n",
    "\n",
    "# 5. Cosmology\n",
    "params = cosmology(args.cosmology_template)\n",
    "cosmo = Cosmology(\n",
    "    h=params.h,\n",
    "    Omega_cdm=params.Omega_m - params.Omega_b - params.Omega_nu_massive,\n",
    "    Omega_b=params.Omega_b,\n",
    "    sigma8=params.sigma_8,\n",
    "    n_s=params.n_s,\n",
    "    Omega_ncdm=params.Omega_nu_massive,\n",
    "    N_eff=3.046,\n",
    "    engine='class'\n",
    ")\n",
    "\n",
    "# 6. Power spectrum. We use the implementation in cosmoprimo\n",
    "pkz = cosmo.get_fourier(engine='class').pk_interpolator()\n",
    "pk = pkz.to_1d(z=0)\n",
    "kh = 10 ** np.linspace(np.log10(1e-4 / cosmo.h), np.log10(1e2), Nk)\n",
    "Pk_wigg = pk(kh) / cosmo.h**3\n",
    "\n",
    "pknow = PowerSpectrumBAOFilter(pk, engine='wallish2018').smooth_pk_interpolator()\n",
    "Pk_nowigg = pknow(kh) / cosmo.h**3\n",
    "\n",
    "k = kh * cosmo.h\n",
    "np.savetxt(f'{savedir}/Pk_full.txt', np.column_stack([k, Pk_wigg, Pk_nowigg]))\n",
    "\n",
    "k_s = 0.2 * cosmo.h\n",
    "ell_BAO = 110 / cosmo.h\n",
    "\n",
    "q = 10 ** np.linspace(np.log10(k.min()), np.log10(k_s), Nk)\n",
    "Pq_nowigg = np.interp(q, k, Pk_nowigg)\n",
    "\n",
    "x = q * ell_BAO\n",
    "j_0 = np.sin(x) / x\n",
    "j_2 = (3 / x**2 - 1) * j_0 - 3 * np.cos(x) / x**2\n",
    "\n",
    "Sigma_0 = np.sqrt(np.trapz(Pq_nowigg * (1 - j_0 + 2 * j_2), q) / (6 * np.pi**2))\n",
    "delta_Sigma_0 = np.sqrt(np.trapz(Pq_nowigg * j_2, q) / (2 * np.pi**2))\n",
    "\n",
    "print([Sigma_0 * cosmo.h, delta_Sigma_0 * cosmo.h])\n",
    "\n",
    "# Calculation of xi_ell(s)\n",
    "\n",
    "def compute_xi_ell(bin_z):\n",
    "    \n",
    "    z = nz_instance.z_average(bin_z)\n",
    "    z_array = nz_instance.z_vector(bin_z)\n",
    "\n",
    "    D = cosmo.growth_factor(z)\n",
    "    f = cosmo.growth_rate(z)\n",
    "\n",
    "    Sigma = D * Sigma_0\n",
    "    delta_Sigma = D * delta_Sigma_0\n",
    "\n",
    "    Sigma_paral = (1 + f) * Sigma\n",
    "    Sigma_perp = Sigma\n",
    "    Sigma_tot_vector = np.sqrt(\n",
    "        mu_vector**2 * Sigma_paral**2 \n",
    "        + (1 - mu_vector**2) * Sigma_perp**2 \n",
    "        + f * mu_vector**2 * (mu_vector**2 - 1) * delta_Sigma**2\n",
    "    )\n",
    "\n",
    "    print(f\"{bin_z} - Computing Pk_ell...\")\n",
    "\n",
    "    def compute_pk_multipoles(k, Pk_wigg, Pk_nowigg):\n",
    "        if args.include_wiggles == '':\n",
    "            pk_term = (Pk_wigg - Pk_nowigg) * np.exp(-k**2 * Sigma_tot_vector**2) + Pk_nowigg\n",
    "        elif args.include_wiggles == '_noBAO':\n",
    "            pk_term = Pk_nowigg\n",
    "\n",
    "        pk_dict = {}\n",
    "        for ell in [0, 2, 4]:\n",
    "            leg = legendre[ell]\n",
    "            coeff = (2 * ell + 1) / 2\n",
    "\n",
    "            pk_dict[f'Pk_{ell}'] = coeff * np.trapz((galaxy_bias[bin_z] + mu_vector**2 * f)**2 * pk_term * leg, mu_vector)\n",
    "            pk_dict[f'Pk_{ell}_bb'] = coeff * np.trapz(pk_term * leg, mu_vector)\n",
    "            pk_dict[f'Pk_{ell}_bf'] = coeff * np.trapz(2 * mu_vector**2 * f * pk_term * leg, mu_vector)\n",
    "            pk_dict[f'Pk_{ell}_ff'] = coeff * np.trapz(mu_vector**4 * f**2 * pk_term * leg, mu_vector)\n",
    "\n",
    "        return pk_dict\n",
    "\n",
    "    pk_ell_dict = {key: np.zeros(len(k)) for key in [\n",
    "        'Pk_0', 'Pk_2', 'Pk_4',\n",
    "        'Pk_0_bb', 'Pk_2_bb', 'Pk_4_bb',\n",
    "        'Pk_0_bf', 'Pk_2_bf', 'Pk_4_bf',\n",
    "        'Pk_0_ff', 'Pk_2_ff', 'Pk_4_ff'\n",
    "    ]}\n",
    "\n",
    "    for i, k_val in enumerate(k):\n",
    "        pk_dict = compute_pk_multipoles(\n",
    "            k_val, Pk_wigg[i], Pk_nowigg[i]\n",
    "        )\n",
    "        for key, value in pk_dict.items():\n",
    "            pk_ell_dict[key][i] = value\n",
    "\n",
    "    np.savetxt(\n",
    "        savedir + f'/Pk_ell_bb_bin{bin_z}.txt', \n",
    "        np.column_stack([k, pk_ell_dict['Pk_0_bb'], pk_ell_dict['Pk_2_bb'], pk_ell_dict['Pk_4_bb']])\n",
    "    )\n",
    "    np.savetxt(\n",
    "        savedir + f'/Pk_ell_bf_bin{bin_z}.txt', \n",
    "        np.column_stack([k, pk_ell_dict['Pk_0_bf'], pk_ell_dict['Pk_2_bf'], pk_ell_dict['Pk_4_bf']])\n",
    "    )\n",
    "    np.savetxt(\n",
    "        savedir + f'/Pk_ell_ff_bin{bin_z}.txt', \n",
    "        np.column_stack([k, pk_ell_dict['Pk_0_ff'], pk_ell_dict['Pk_2_ff'], pk_ell_dict['Pk_4_ff']])\n",
    "    )\n",
    "\n",
    "    diff_check = [\n",
    "        abs(pk_ell_dict['Pk_0'] - pk_ell_dict['Pk_0_bb'] * galaxy_bias[bin_z]**2 - pk_ell_dict['Pk_0_bf'] * galaxy_bias[bin_z] - pk_ell_dict['Pk_0_ff']).max(),\n",
    "        abs(pk_ell_dict['Pk_2'] - pk_ell_dict['Pk_2_bb'] * galaxy_bias[bin_z]**2 - pk_ell_dict['Pk_2_bf'] * galaxy_bias[bin_z] - pk_ell_dict['Pk_2_ff']).max(),\n",
    "        abs(pk_ell_dict['Pk_4'] - pk_ell_dict['Pk_4_bb'] * galaxy_bias[bin_z]**2 - pk_ell_dict['Pk_4_bf'] * galaxy_bias[bin_z] - pk_ell_dict['Pk_4_ff']).max(),\n",
    "    ]\n",
    "\n",
    "    print(f\"These should be 0: {diff_check}\")\n",
    "    print(f\"{bin_z} - Pk_ell computed!\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"{bin_z} - Computing xi_ell...\")\n",
    "\n",
    "    def compute_xi_multipoles(r):\n",
    "        x = k * r\n",
    "        x_square_inv = 1 / x**2\n",
    "        sinc_x = np.sin(x) / x\n",
    "        cos_x_redef = np.cos(x) * x_square_inv\n",
    "\n",
    "        j_0_x = sinc_x\n",
    "        j_2_x = (3 * x_square_inv - 1) * sinc_x - 3 * cos_x_redef\n",
    "        j_4_x = 5 * (2 - 21 * x_square_inv) * cos_x_redef + (1 - 45 * x_square_inv + 105 * x_square_inv**2) * sinc_x\n",
    "\n",
    "        xi_dict = {}\n",
    "        for ell, j_ell_x in zip([0, 2, 4], [j_0_x, j_2_x, j_4_x]):\n",
    "            xi_dict[f'xi_{ell}'] = np.trapz(j_ell_x * k**2 / (2 * np.pi**2) * pk_ell_dict[f'Pk_{ell}'], k)\n",
    "            xi_dict[f'xi_{ell}_bb'] = np.trapz(j_ell_x * k**2 / (2 * np.pi**2) * pk_ell_dict[f'Pk_{ell}_bb'], k)\n",
    "            xi_dict[f'xi_{ell}_bf'] = np.trapz(j_ell_x * k**2 / (2 * np.pi**2) * pk_ell_dict[f'Pk_{ell}_bf'], k)\n",
    "            xi_dict[f'xi_{ell}_ff'] = np.trapz(j_ell_x * k**2 / (2 * np.pi**2) * pk_ell_dict[f'Pk_{ell}_ff'], k)\n",
    "\n",
    "        return xi_dict\n",
    "\n",
    "    xi_ell_dict = {key: np.zeros(Nr) for key in [\n",
    "        'xi_0', 'xi_2', 'xi_4',\n",
    "        'xi_0_bb', 'xi_2_bb', 'xi_4_bb',\n",
    "        'xi_0_bf', 'xi_2_bf', 'xi_4_bf',\n",
    "        'xi_0_ff', 'xi_2_ff', 'xi_4_ff'\n",
    "    ]}\n",
    "\n",
    "    for i, r_12 in enumerate(r_12_vector):\n",
    "        xi_dict = compute_xi_multipoles(r_12)\n",
    "        for key, value in xi_dict.items():\n",
    "            xi_ell_dict[key][i] = value\n",
    "\n",
    "        if (i + 1) % (Nr // 10) == 0:\n",
    "            print(f\"{bin_z} - {int((i + 1) / Nr * 100)}%\")\n",
    "\n",
    "    np.savetxt(\n",
    "        savedir + f'/xi_ell_bb_bin{bin_z}.txt',\n",
    "        np.column_stack([r_12_vector, xi_ell_dict['xi_0_bb'], xi_ell_dict['xi_2_bb'], xi_ell_dict['xi_4_bb']])\n",
    "    )\n",
    "    np.savetxt(\n",
    "        savedir + f'/xi_ell_bf_bin{bin_z}.txt',\n",
    "        np.column_stack([r_12_vector, xi_ell_dict['xi_0_bf'], xi_ell_dict['xi_2_bf'], xi_ell_dict['xi_4_bf']])\n",
    "    )\n",
    "    np.savetxt(\n",
    "        savedir + f'/xi_ell_ff_bin{bin_z}.txt',\n",
    "        np.column_stack([r_12_vector, xi_ell_dict['xi_0_ff'], xi_ell_dict['xi_2_ff'], xi_ell_dict['xi_4_ff']])\n",
    "    )\n",
    "\n",
    "    diff_check = [\n",
    "        abs(xi_ell_dict['xi_0'] - xi_ell_dict['xi_0_bb'] * galaxy_bias[bin_z]**2 - xi_ell_dict['xi_0_bf'] * galaxy_bias[bin_z] - xi_ell_dict['xi_0_ff']).max(),\n",
    "        abs(xi_ell_dict['xi_2'] - xi_ell_dict['xi_2_bb'] * galaxy_bias[bin_z]**2 - xi_ell_dict['xi_2_bf'] * galaxy_bias[bin_z] - xi_ell_dict['xi_2_ff']).max(),\n",
    "        abs(xi_ell_dict['xi_4'] - xi_ell_dict['xi_4_bb'] * galaxy_bias[bin_z]**2 - xi_ell_dict['xi_4_bf'] * galaxy_bias[bin_z] - xi_ell_dict['xi_4_ff']).max(),\n",
    "    ]\n",
    "\n",
    "    print(f\"These should be 0: {diff_check}\")\n",
    "    print(f\"{bin_z} - xi_ell computed!\")\n",
    "    \n",
    "    return xi_ell_dict\n",
    "\n",
    "pool = multiprocessing.Pool(nz_instance.nbins)\n",
    "xi_ell_dict = pool.map(compute_xi_ell, range(nz_instance.nbins))\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "# Calculation of w(theta)\n",
    "\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "\n",
    "for bin_z in range(nz_instance.nbins):\n",
    "\n",
    "    z_values = nz_instance.z_vector(bin_z, Nz=Nz)\n",
    "    D_values = cosmo.growth_factor(z_values)\n",
    "    phi_values = nz_instance.nz_interp(z_values, bin_z) * D_values\n",
    "    r_values = cosmo.comoving_radial_distance(z_values)/cosmo.h\n",
    "\n",
    "    integrand_results = {key: np.zeros((len(z_values), len(z_values))) for key in [\n",
    "        'integrand', 'integrand_bb', 'integrand_bf', 'integrand_ff'\n",
    "    ]}\n",
    "    \n",
    "    print(f\"{bin_z} - Computing wtheta...\")\n",
    "\n",
    "    def wtheta_calculator(theta):\n",
    "        for i in np.arange(0, len(z_values)):\n",
    "            for j in np.arange(0, len(z_values)):\n",
    "                if j < i:\n",
    "                    for key in integrand_results.keys():\n",
    "                        integrand_results[key][i, j] = integrand_results[key][j, i]\n",
    "                else:\n",
    "                    r_12 = np.sqrt(r_values[i]**2 + r_values[j]**2 - 2 * r_values[i] * r_values[j] * np.cos(theta))\n",
    "                    mu = (r_values[j] - r_values[i]) / r_12\n",
    "                    try:\n",
    "                        integrand_results['integrand'][i, j] = phi_values[i] * phi_values[j] * sum([\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_0']) * np.interp(mu, mu_vector, legendre[0]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_2']) * np.interp(mu, mu_vector, legendre[2]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_4']) * np.interp(mu, mu_vector, legendre[4])\n",
    "                        ])\n",
    "                        integrand_results['integrand_bb'][i, j] = phi_values[i] * phi_values[j] * sum([\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_0_bb']) * np.interp(mu, mu_vector, legendre[0]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_2_bb']) * np.interp(mu, mu_vector, legendre[2]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_4_bb']) * np.interp(mu, mu_vector, legendre[4])\n",
    "                        ])\n",
    "                        integrand_results['integrand_bf'][i, j] = phi_values[i] * phi_values[j] * sum([\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_0_bf']) * np.interp(mu, mu_vector, legendre[0]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_2_bf']) * np.interp(mu, mu_vector, legendre[2]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_4_bf']) * np.interp(mu, mu_vector, legendre[4])\n",
    "                        ])\n",
    "                        integrand_results['integrand_ff'][i, j] = phi_values[i] * phi_values[j] * sum([\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_0_ff']) * np.interp(mu, mu_vector, legendre[0]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_2_ff']) * np.interp(mu, mu_vector, legendre[2]),\n",
    "                            np.interp(r_12, r_12_vector, xi_ell_dict[bin_z]['xi_4_ff']) * np.interp(mu, mu_vector, legendre[4])\n",
    "                        ])\n",
    "                    except ValueError:\n",
    "                        print([r_12, mu])\n",
    "\n",
    "        w_dict = {}\n",
    "        w_dict['wtheta'] = np.trapz(np.trapz(integrand_results['integrand'], z_values), z_values)\n",
    "        w_dict['wtheta_bb'] = np.trapz(np.trapz(integrand_results['integrand_bb'], z_values), z_values)\n",
    "        w_dict['wtheta_bf'] = np.trapz(np.trapz(integrand_results['integrand_bf'], z_values), z_values)\n",
    "        w_dict['wtheta_ff'] = np.trapz(np.trapz(integrand_results['integrand_ff'], z_values), z_values)\n",
    "\n",
    "        return w_dict\n",
    "    \n",
    "    pool = multiprocessing.Pool(n_cpu)\n",
    "    w_dict = pool.map(wtheta_calculator, theta)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    wtheta_dict = {'wtheta': np.array([w_dict[i]['wtheta'] for i in range(len(theta))]),\n",
    "                   'wtheta_bb': np.array([w_dict[i]['wtheta_bb'] for i in range(len(theta))]),\n",
    "                   'wtheta_bf': np.array([w_dict[i]['wtheta_bf'] for i in range(len(theta))]),\n",
    "                   'wtheta_ff': np.array([w_dict[i]['wtheta_ff'] for i in range(len(theta))])\n",
    "                  }\n",
    "\n",
    "    np.savetxt(\n",
    "        savedir + f'/wtheta_bb_bin{bin_z}.txt',\n",
    "        np.column_stack([theta, wtheta_dict['wtheta_bb'], wtheta_dict['wtheta_bb'], wtheta_dict['wtheta_bb']])\n",
    "    )\n",
    "    np.savetxt(\n",
    "        savedir + f'/wtheta_bf_bin{bin_z}.txt',\n",
    "        np.column_stack([theta, wtheta_dict['wtheta_bf'], wtheta_dict['wtheta_bf'], wtheta_dict['wtheta_bf']])\n",
    "    )\n",
    "    np.savetxt(\n",
    "        savedir + f'/wtheta_ff_bin{bin_z}.txt',\n",
    "        np.column_stack([theta, wtheta_dict['wtheta_ff'], wtheta_dict['wtheta_ff'], wtheta_dict['wtheta_ff']])\n",
    "    )\n",
    "\n",
    "    diff_check = [\n",
    "        abs(wtheta_dict['wtheta'] - wtheta_dict['wtheta_bb'] * galaxy_bias[bin_z]**2 - wtheta_dict['wtheta_bf'] * galaxy_bias[bin_z] - wtheta_dict['wtheta_ff']).max(),\n",
    "    ]\n",
    "\n",
    "    print(f\"This should be 0: {diff_check}\")\n",
    "    print(f\"{bin_z} - wtheta computed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c2f51-4c09-48ba-8b81-72739558c2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e06bd-dedc-4a15-9e6e-adf070b91fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14e6a1-9f6f-4cbb-a668-11cee769b72e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f228e-2649-4d53-8f7c-a5ff8cea4cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b10e6-344e-43b7-85bd-4b4811222193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmodesi-main",
   "language": "python",
   "name": "cosmodesi-main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
